{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Scrape the LangChain documentation into a ChromaDB Vector Database and use it for a GPT-4 chatbot  to talk with it!\n",
    "\n",
    "In this notebook, I will introduce you to vector databases. I will:\n",
    "- Web scrape the LangChain documentation\n",
    "- Store the LangChain documentation in a Chroma DB vector database\n",
    "- Create a retriever to retrieve the desired information\n",
    "- Create a Q&A chatbot with GPT-4\n",
    "- Show how you can delete and reopen a vector database locally to save space\n",
    "Visualise your vector database (very cool, read till the end!)\n",
    "\n",
    "This notebook is connected to a medium article: [Medium articles](https://medium.com/@rubentak)\n",
    "\n",
    "ref: https://medium.com/@rubentak/unleashing-the-power-of-intelligent-chatbots-with-gpt-4-and-vector-databases-a-step-by-step-8027e2ce9e78"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T16:41:32.242590Z",
     "start_time": "2023-06-19T16:41:32.048150Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "def extract_urls_from_page(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        urls = set()\n",
    "\n",
    "        for link in soup.find_all('a', href=True):\n",
    "            absolute_url = urljoin(url, link['href'])\n",
    "            urls.add(absolute_url)\n",
    "\n",
    "        return urls\n",
    "    else:\n",
    "        print(f\"Failed to fetch the page: {response.status_code}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T16:41:32.721007Z",
     "start_time": "2023-06-19T16:41:32.715151Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found URLs:\n",
      "https://docs.oracle.com/en/cloud/get-started/subscriptions-cloud/get-trial-or-subscription.html\n",
      "https://docs.cloud.oracle.com/iaas/Content/home.htm\n",
      "https://docs.oracle.com/index.html\n",
      "https://docs.oracle.com/en/cloud/marketplace/index.html\n",
      "https://docs.oracle.com/pls/topic/lookup?ctx=en/legal&id=cpyr\n",
      "https://www.oracle.com/cloud/free/\n",
      "https://docs.oracle.com/pls/topic/lookup?ctx=en/legal&id=about\n",
      "https://docs.oracle.com/en/cloud/cloud-at-customer/index.html\n",
      "https://docs.oracle.com/en/cloud/get-started/index.html\n",
      "https://docs.oracle.com/en/cloud/paas/index.html\n",
      "https://docs.oracle.com/pls/topic/lookup?ctx=en/legal&id=privacy\n",
      "https://docs.oracle.com/en/cloud/saas/index.html\n",
      "https://docs.oracle.com/\n",
      "https://docs.oracle.com/en/cloud/index.html\n",
      "https://docs.oracle.com/en/cloud/get-started/subscriptions-cloud/index.html\n",
      "https://docs.oracle.com/pls/topic/lookup?ctx=en/legal&id=contact\n"
     ]
    }
   ],
   "source": [
    "target_url = \"https://docs.oracle.com/en/cloud/get-started/index.html\"  # Replace with the URL you want to scrape\n",
    "found_urls = extract_urls_from_page(target_url)\n",
    "\n",
    "print(\"Found URLs:\")\n",
    "for url in found_urls:\n",
    "    print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-13T16:19:58.593491Z",
     "start_time": "2023-06-13T16:19:58.585704Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "def save_content(link_list):\n",
    "    for i, link in enumerate(link_list):\n",
    "        html_data = get_data(link)\n",
    "        soup = BeautifulSoup(html_data, \"html.parser\")\n",
    "        text = soup.get_text()\n",
    "\n",
    "        # Remove the first 835 lines\n",
    "        lines = text.splitlines()\n",
    "        cleaned_text = \"\\n\".join(lines)\n",
    "\n",
    "        # Get the first 3 words in the cleaned text\n",
    "        words = cleaned_text.split()[:3]\n",
    "        file_name_prefix = \"_\".join(words)\n",
    "\n",
    "        # Replace special characters and spaces with an underscore\n",
    "        file_name_prefix = re.sub(r\"[^a-zA-Z0-9]+\", \"_\", file_name_prefix)\n",
    "\n",
    "        # Get the current working directory\n",
    "        current_dir = os.getcwd()\n",
    "\n",
    "        # Move up one level to the parent directory\n",
    "        parent_dir = os.path.dirname(current_dir)\n",
    "\n",
    "        # Set the path to the data folder\n",
    "        data_folder = os.path.join(parent_dir, \"data/langchain_doc\")\n",
    "\n",
    "        # Create the data folder if it doesn't exist\n",
    "        if not os.path.exists(data_folder):\n",
    "            os.makedirs(data_folder)\n",
    "\n",
    "        # Set the path to the output file\n",
    "        output_file = os.path.join(data_folder, f\"{i}_{file_name_prefix}.txt\")\n",
    "\n",
    "        # Save the cleaned content to the output file\n",
    "        with open(output_file, \"w\") as f:\n",
    "            f.write(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-13T16:27:42.481314Z",
     "start_time": "2023-06-13T16:19:59.394583Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# save the content of the links into txt files\n",
    "save_content(found_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Q&A bot with langchain over a directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T16:41:39.120259Z",
     "start_time": "2023-06-19T16:41:37.999101Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import os\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import DirectoryLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T16:41:51.728890Z",
     "start_time": "2023-06-19T16:41:51.721987Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Create a new openai api key\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\n",
    "# set up openai api key\n",
    "openai_api_key = os.environ.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T16:42:12.868777Z",
     "start_time": "2023-06-19T16:41:56.716136Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "679"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print number of txt files in directory\n",
    "loader = DirectoryLoader('/Users/erictak/PycharmProjects/langchain/data/langchain_doc', glob=\"./*.txt\")\n",
    "doc = loader.load ( )\n",
    "len(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T16:42:15.006310Z",
     "start_time": "2023-06-19T16:42:14.844815Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Splitting the text into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter (chunk_size=1000, chunk_overlap=200)\n",
    "texts = text_splitter.split_documents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T16:42:15.204405Z",
     "start_time": "2023-06-19T16:42:15.197499Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5576"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of chunks\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T16:42:16.482727Z",
     "start_time": "2023-06-19T16:42:16.460830Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Twitter\\n\\nContents\\n\\nInstallation and Setup\\n\\nDocument Loader\\n\\nTwitter#\\n\\nTwitter is an online social media and social networking service.\\n\\nInstallation and Setup#\\n\\npip install tweepy\\n\\nWe must initialize the loader with the Twitter API token, and we need to set up the Twitter username.\\n\\nDocument Loader#\\n\\nSee a usage example.\\n\\nfrom langchain.document_loaders import TwitterTweetLoader\\n\\nprevious\\n\\nTrello\\n\\nnext\\n\\nUnstructured\\n\\nContents\\n\\nInstallation and Setup\\n\\nDocument Loader\\n\\nBy Harrison Chase\\n\\nÂ© Copyright 2023, Harrison Chase.\\n\\nLast updated on Jun 13, 2023.', metadata={'source': '/Users/erictak/PycharmProjects/langchain/data/langchain_doc/592_Twitter_Contents_Installation.txt'})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the first chunk\n",
    "texts[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Data base creation with ChromaDB\n",
    "\n",
    "https://www.youtube.com/watch?v=3yPBVii7Ct0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T16:43:22.594752Z",
     "start_time": "2023-06-19T16:42:18.312526Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB with persistence: data will be stored in: db\n"
     ]
    }
   ],
   "source": [
    "# Embed and store the texts\n",
    "# Supplying a persist_directory will store the embeddings on disk\n",
    "persist_directory = 'db'\n",
    "\n",
    "# OpenAI embeddings\n",
    "embedding = OpenAIEmbeddings()\n",
    "\n",
    "vectordb = Chroma.from_documents(documents=texts,\n",
    "                                 embedding=embedding,\n",
    "                                 persist_directory=persist_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T16:43:27.867043Z",
     "start_time": "2023-06-19T16:43:22.595566Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "125530d1ac8c4ce3b0eac61cf501ec54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='100%'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Persist the db to disk\n",
    "vectordb.persist()\n",
    "vectordb = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T16:43:31.243716Z",
     "start_time": "2023-06-19T16:43:29.911945Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB with persistence: data will be stored in: db\n"
     ]
    }
   ],
   "source": [
    "# Now we can load the persisted database from disk, and use it as normal.\n",
    "vectordb = Chroma(persist_directory=persist_directory,\n",
    "                  embedding_function=embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Create retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T16:26:30.027619Z",
     "start_time": "2023-06-19T16:26:30.025333Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T16:26:30.878277Z",
     "start_time": "2023-06-19T16:26:30.666287Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "docs = retriever.get_relevant_documents(\"What to do when getting started?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T16:26:31.158685Z",
     "start_time": "2023-06-19T16:26:31.152005Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Step 1: Create Tools# Agents are largely defined by the tools they can use. If you have a specific task you want the agent to accomplish, you have to give it access to the right tools. We have many tools natively in LangChain, so you should first look to see if any of them meet your needs. But we also make it easy to define a custom tool, so if you need custom tools you should absolutely do that.\\n\\n(Optional) Step 2: Modify Agent# The built-in LangChain agent types are designed to work well in generic situations, but you may be able to improve performance by modifying the agent implementation. There are several ways you could do this:\\n\\nModify the base prompt. This can be used to give the agent more context on how it should behave, etc. Modify the output parser. This is necessary if the agent is having trouble parsing the language model output.', metadata={'source': '/Users/erictak/PycharmProjects/langchain/data/langchain_doc/644_Agents_Contents_Create.txt'}),\n",
       " Document(page_content='Step 1: Create Tools# Agents are largely defined by the tools they can use. If you have a specific task you want the agent to accomplish, you have to give it access to the right tools. We have many tools natively in LangChain, so you should first look to see if any of them meet your needs. But we also make it easy to define a custom tool, so if you need custom tools you should absolutely do that.\\n\\n(Optional) Step 2: Modify Agent# The built-in LangChain agent types are designed to work well in generic situations, but you may be able to improve performance by modifying the agent implementation. There are several ways you could do this:\\n\\nModify the base prompt. This can be used to give the agent more context on how it should behave, etc. Modify the output parser. This is necessary if the agent is having trouble parsing the language model output.', metadata={'source': '/Users/erictak/PycharmProjects/langchain/data/langchain_doc/644_Agents_Contents_Create.txt'}),\n",
       " Document(page_content='Step 1: Create Tools# Agents are largely defined by the tools they can use. If you have a specific task you want the agent to accomplish, you have to give it access to the right tools. We have many tools natively in LangChain, so you should first look to see if any of them meet your needs. But we also make it easy to define a custom tool, so if you need custom tools you should absolutely do that.\\n\\n(Optional) Step 2: Modify Agent# The built-in LangChain agent types are designed to work well in generic situations, but you may be able to improve performance by modifying the agent implementation. There are several ways you could do this:\\n\\nModify the base prompt. This can be used to give the agent more context on how it should behave, etc. Modify the output parser. This is necessary if the agent is having trouble parsing the language model output.', metadata={'source': '/Users/erictak/PycharmProjects/langchain/data/langchain_doc/644_Agents_Contents_Create.txt'}),\n",
       " Document(page_content='Step 1: Create Tools# Agents are largely defined by the tools they can use. If you have a specific task you want the agent to accomplish, you have to give it access to the right tools. We have many tools natively in LangChain, so you should first look to see if any of them meet your needs. But we also make it easy to define a custom tool, so if you need custom tools you should absolutely do that.\\n\\n(Optional) Step 2: Modify Agent# The built-in LangChain agent types are designed to work well in generic situations, but you may be able to improve performance by modifying the agent implementation. There are several ways you could do this:\\n\\nModify the base prompt. This can be used to give the agent more context on how it should behave, etc. Modify the output parser. This is necessary if the agent is having trouble parsing the language model output.', metadata={'source': '/Users/erictak/PycharmProjects/langchain/data/langchain_doc/426_Agents_Contents_Create.txt'})]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T16:26:31.757606Z",
     "start_time": "2023-06-19T16:26:31.753080Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T16:26:32.357106Z",
     "start_time": "2023-06-19T16:26:32.352369Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T16:26:32.812894Z",
     "start_time": "2023-06-19T16:26:32.810205Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'similarity'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.search_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T16:26:34.043554Z",
     "start_time": "2023-06-19T16:26:34.016639Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'k': 2}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.search_kwargs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Create a question answering chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T16:27:30.194519Z",
     "start_time": "2023-06-19T16:27:30.192880Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Create the chain to answer questions\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=OpenAI(),\n",
    "                                  chain_type=\"stuff\",\n",
    "                                  retriever=retriever,\n",
    "                                  return_source_documents=True,\n",
    "                                  verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T16:27:30.714970Z",
     "start_time": "2023-06-19T16:27:30.710251Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Cite sources\n",
    "def process_llm_response(llm_response):\n",
    "    print(llm_response['result'])\n",
    "    print('\\n\\nSources:')\n",
    "    for source in llm_response[\"source_documents\"]:\n",
    "        print(source.metadata['source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T16:27:34.967867Z",
     "start_time": "2023-06-19T16:27:31.647843Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " Step 1: Create Tools (Optional), Step 2: Modify Agent (Optional), Step 3: Modify Agent Executor.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/Users/erictak/PycharmProjects/langchain/data/langchain_doc/426_Agents_Contents_Create.txt\n",
      "/Users/erictak/PycharmProjects/langchain/data/langchain_doc/644_Agents_Contents_Create.txt\n"
     ]
    }
   ],
   "source": [
    "# Question\n",
    "query = \"What are the steps of the Quickstart Guide?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T16:28:07.848794Z",
     "start_time": "2023-06-19T16:28:02.784404Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " Custom Agent, Custom LLM Agent, Custom LLM Agent (with a ChatModel), Custom MRKL Agent, Custom MultiAction Agent, Custom Agent with Tool Retrieval, Conversation Agent (for Chat Models), Conversation Agent MRKL, MRKL Chat, ReAct, Self Ask With Search, Structured Tool Chat Agent.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/Users/erictak/PycharmProjects/langchain/data/langchain_doc/382_Agents_Agents_Note.txt\n",
      "/Users/erictak/PycharmProjects/langchain/data/langchain_doc/382_Agents_Agents_Note.txt\n"
     ]
    }
   ],
   "source": [
    "# Break it down\n",
    "query = \"What are all agent types?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)\n",
    "#llm_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T16:28:14.817109Z",
     "start_time": "2023-06-19T16:28:14.812659Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('similarity', <langchain.vectorstores.chroma.Chroma at 0x7f8dba0c1ff0>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_chain.retriever.search_type , qa_chain.retriever.vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T16:28:15.148649Z",
     "start_time": "2023-06-19T16:28:15.140236Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "{context}\n",
      "\n",
      "Question: {question}\n",
      "Helpful Answer:\n"
     ]
    }
   ],
   "source": [
    "print(qa_chain.combine_documents_chain.llm_chain.prompt.template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Deleteing the DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-13T17:27:10.552238Z",
     "start_time": "2023-06-13T17:27:05.048974Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating: db/ (stored 0%)\r\n",
      "updating: db/chroma-embeddings.parquet (deflated 29%)\r\n",
      "updating: db/index/ (stored 0%)\r\n",
      "updating: db/index/index_metadata_b9a5e02f-ebd0-4b13-8858-b30b211c4546.pkl (deflated 5%)\r\n",
      "updating: db/index/id_to_uuid_b9a5e02f-ebd0-4b13-8858-b30b211c4546.pkl (deflated 37%)\r\n",
      "updating: db/index/uuid_to_id_d80886e4-65e1-4231-8c73-99ff58d68061.pkl (deflated 39%)\r\n",
      "updating: db/index/index_b9a5e02f-ebd0-4b13-8858-b30b211c4546.bin (deflated 17%)\r\n",
      "updating: db/index/index_d80886e4-65e1-4231-8c73-99ff58d68061.bin (deflated 17%)\r\n",
      "updating: db/index/uuid_to_id_b9a5e02f-ebd0-4b13-8858-b30b211c4546.pkl (deflated 41%)\r\n",
      "updating: db/index/id_to_uuid_d80886e4-65e1-4231-8c73-99ff58d68061.pkl (deflated 32%)\r\n",
      "updating: db/index/index_metadata_d80886e4-65e1-4231-8c73-99ff58d68061.pkl (deflated 5%)\r\n",
      "updating: db/chroma-collections.parquet (deflated 50%)\r\n",
      "updating: db/.DS_Store (deflated 96%)\r\n"
     ]
    }
   ],
   "source": [
    "!zip -r db.zip ./db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-13T17:27:10.802965Z",
     "start_time": "2023-06-13T17:27:10.552089Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# To clean up, you can delete the collection\n",
    "vectordb.delete_collection()\n",
    "vectordb.persist()\n",
    "\n",
    "# Delete the directory\n",
    "!rm -rf db/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Starting again loading the db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T16:30:09.309839Z",
     "start_time": "2023-06-19T16:29:00.698188Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  db.zip\r\n",
      "replace db/chroma-embeddings.parquet? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\r\n"
     ]
    }
   ],
   "source": [
    "!unzip db.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T16:30:13.801920Z",
     "start_time": "2023-06-19T16:30:12.530863Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB with persistence: data will be stored in: db\n"
     ]
    }
   ],
   "source": [
    "persist_directory = 'db'\n",
    "embedding = OpenAIEmbeddings()\n",
    "\n",
    "vectordb2 = Chroma(persist_directory=persist_directory,\n",
    "                  embedding_function=embedding,\n",
    "                   )\n",
    "\n",
    "retriever = vectordb2.as_retriever(search_kwargs={\"k\": 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Usung turbo GPT API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T16:30:15.131031Z",
     "start_time": "2023-06-19T16:30:15.126008Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Set up the turbo LLM\n",
    "turbo_llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    model_name='gpt-3.5-turbo'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T16:30:15.535025Z",
     "start_time": "2023-06-19T16:30:15.531668Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Create the chain to answer questions\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=turbo_llm,\n",
    "                                  chain_type=\"stuff\",\n",
    "                                  retriever=retriever,\n",
    "                                  return_source_documents=True,\n",
    "                                  verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T16:30:16.283860Z",
     "start_time": "2023-06-19T16:30:16.275813Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Cite sources\n",
    "def process_llm_response(llm_response):\n",
    "    print(llm_response['result'])\n",
    "    print('\\n\\nSources:')\n",
    "    for source in llm_response[\"source_documents\"]:\n",
    "        print(source.metadata['source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T16:30:22.264885Z",
     "start_time": "2023-06-19T16:30:16.942379Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "There are two main types of agents mentioned in the context: Action Agents and Plan-and-Execute Agents. Action Agents decide the actions to take and execute those actions one at a time, while Plan-and-Execute Agents first decide a plan of actions to take, and then execute those actions one at a time.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/Users/erictak/PycharmProjects/langchain/data/langchain_doc/639_Agents_Contents_Action.txt\n",
      "/Users/erictak/PycharmProjects/langchain/data/langchain_doc/344_Agents_Contents_Action.txt\n"
     ]
    }
   ],
   "source": [
    "# Question\n",
    "query = \"What are the agent types?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T16:30:23.332015Z",
     "start_time": "2023-06-19T16:30:23.325565Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use the following pieces of context to answer the users question. \n",
      "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "----------------\n",
      "{context}\n"
     ]
    }
   ],
   "source": [
    "print(qa_chain.combine_documents_chain.llm_chain.prompt.messages[0].prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T16:30:24.189842Z",
     "start_time": "2023-06-19T16:30:24.183626Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{question}\n"
     ]
    }
   ],
   "source": [
    "print(qa_chain.combine_documents_chain.llm_chain.prompt.messages[1].prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T16:30:24.724602Z",
     "start_time": "2023-06-19T16:30:24.717401Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Visualizing the Vector db\n",
    "https://github.com/mtybadger/chromaviz?ref=reactjsexample.com\n",
    "\n",
    "https://github.com/avantrio/chroma-viewer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from chromaviz import visualize_collection\n",
    "visualize_collection(vectordb._collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
