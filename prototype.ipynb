{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Scrape the LangChain documentation into a ChromaDB Vector Database and use it for a GPT-4 chatbot  to talk with it!\n",
    "\n",
    "In this notebook, I will introduce you to vector databases. I will:\n",
    "- Web scrape the LangChain documentation\n",
    "- Store the LangChain documentation in a Chroma DB vector database\n",
    "- Create a retriever to retrieve the desired information\n",
    "- Create a Q&A chatbot with GPT-4\n",
    "- Show how you can delete and reopen a vector database locally to save space\n",
    "Visualise your vector database (very cool, read till the end!)\n",
    "\n",
    "This notebook is connected to a medium article: [Medium articles](https://medium.com/@rubentak)\n",
    "\n",
    "ref: https://medium.com/@rubentak/unleashing-the-power-of-intelligent-chatbots-with-gpt-4-and-vector-databases-a-step-by-step-8027e2ce9e78"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-4.11.2-py3-none-any.whl (7.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting trio~=0.17\n",
      "  Downloading trio-0.22.2-py3-none-any.whl (400 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.2/400.2 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting trio-websocket~=0.9\n",
      "  Downloading trio_websocket-0.10.3-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /home/zhuoli/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from selenium) (2022.12.7)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in /home/zhuoli/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from selenium) (2.0.4)\n",
      "Collecting outcome\n",
      "  Downloading outcome-1.2.0-py2.py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in /home/zhuoli/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from trio~=0.17->selenium) (1.1.2)\n",
      "Collecting sortedcontainers\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: attrs>=20.1.0 in /home/zhuoli/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from trio~=0.17->selenium) (23.1.0)\n",
      "Requirement already satisfied: sniffio in /home/zhuoli/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: idna in /home/zhuoli/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from trio~=0.17->selenium) (2.10)\n",
      "Requirement already satisfied: wsproto>=0.14 in /home/zhuoli/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Collecting pysocks!=1.5.7,<2.0,>=1.5.6\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /home/zhuoli/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Installing collected packages: sortedcontainers, pysocks, outcome, trio, trio-websocket, selenium\n",
      "Successfully installed outcome-1.2.0 pysocks-1.7.1 selenium-4.11.2 sortedcontainers-2.4.0 trio-0.22.2 trio-websocket-0.10.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T16:41:32.242590Z",
     "start_time": "2023-06-19T16:41:32.048150Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "def extract_urls_with_js(url):\n",
    "    options = Options()\n",
    "    options.headless = True  # Run Chrome in headless mode\n",
    "\n",
    "    # Provide the path to your ChromeDriver executable\n",
    "    driver_path = \"/home/zhuoli/Projects/github/zhuoli/data/chromedriver\"\n",
    "\n",
    "    # Initialize Chrome WebDriver\n",
    "    driver = webdriver.Chrome(driver_path)\n",
    "\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        \n",
    "        # Wait for the dynamic content to load (you might need to adjust the wait time)\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        wait.until(EC.presence_of_element_located((By.ID, \"app\")))\n",
    "\n",
    "        # Get the page source after JavaScript execution\n",
    "        page_source = driver.page_source\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "    # Now, parse the page source with BeautifulSoup as before\n",
    "    soup = BeautifulSoup(page_source, 'html.parser')\n",
    "    urls = set()\n",
    "\n",
    "    for link in soup.find_all('a', href=True):\n",
    "        absolute_url = urljoin(url, link['href'])\n",
    "        urls.add(absolute_url)\n",
    "\n",
    "    return urls\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T16:41:32.721007Z",
     "start_time": "2023-06-19T16:41:32.715151Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28439/3022003982.py:11: DeprecationWarning: headless property is deprecated, instead use add_argument('--headless') or add_argument('--headless=new')\n",
      "  options.headless = True  # Run Chrome in headless mode\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'capabilities'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/3.10.9/lib/python3.10/site-packages/selenium/webdriver/common/driver_finder.py:38\u001b[0m, in \u001b[0;36mDriverFinder.get_path\u001b[0;34m(service, options)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 38\u001b[0m     path \u001b[38;5;241m=\u001b[39m \u001b[43mSeleniumManager\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdriver_location\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m path\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.9/lib/python3.10/site-packages/selenium/webdriver/common/selenium_manager.py:71\u001b[0m, in \u001b[0;36mSeleniumManager.driver_location\u001b[0;34m(self, options)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03mDetermines the path of the correct driver.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;124;03m:Args:\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;124;03m - browser: which browser to get the driver path for.\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;124;03m:Returns: The driver path to use\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 71\u001b[0m browser \u001b[38;5;241m=\u001b[39m \u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcapabilities\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbrowserName\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     73\u001b[0m args \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_binary()), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--browser\u001b[39m\u001b[38;5;124m\"\u001b[39m, browser]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'capabilities'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[73], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m target_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://docs.oracle.com/en-us/iaas/api/#/\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Replace with the URL you want to scrape\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m found_urls \u001b[38;5;241m=\u001b[39m \u001b[43mextract_urls_with_js\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound URLs:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m url \u001b[38;5;129;01min\u001b[39;00m found_urls:\n",
      "Cell \u001b[0;32mIn[72], line 17\u001b[0m, in \u001b[0;36mextract_urls_with_js\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m     14\u001b[0m driver_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/zhuoli/Projects/github/zhuoli/data/chromedriver\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Initialize Chrome WebDriver\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m driver \u001b[38;5;241m=\u001b[39m \u001b[43mwebdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChrome\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     20\u001b[0m     driver\u001b[38;5;241m.\u001b[39mget(url)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.9/lib/python3.10/site-packages/selenium/webdriver/chrome/webdriver.py:45\u001b[0m, in \u001b[0;36mWebDriver.__init__\u001b[0;34m(self, options, service, keep_alive)\u001b[0m\n\u001b[1;32m     42\u001b[0m service \u001b[38;5;241m=\u001b[39m service \u001b[38;5;28;01mif\u001b[39;00m service \u001b[38;5;28;01melse\u001b[39;00m Service()\n\u001b[1;32m     43\u001b[0m options \u001b[38;5;241m=\u001b[39m options \u001b[38;5;28;01mif\u001b[39;00m options \u001b[38;5;28;01melse\u001b[39;00m Options()\n\u001b[0;32m---> 45\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mDesiredCapabilities\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCHROME\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbrowserName\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgoog\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43mservice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.9/lib/python3.10/site-packages/selenium/webdriver/chromium/webdriver.py:51\u001b[0m, in \u001b[0;36mChromiumDriver.__init__\u001b[0;34m(self, browser_name, vendor_prefix, options, service, keep_alive)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvendor_prefix \u001b[38;5;241m=\u001b[39m vendor_prefix\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice \u001b[38;5;241m=\u001b[39m service\n\u001b[0;32m---> 51\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice\u001b[38;5;241m.\u001b[39mpath \u001b[38;5;241m=\u001b[39m \u001b[43mDriverFinder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_path\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mservice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.9/lib/python3.10/site-packages/selenium/webdriver/common/driver_finder.py:40\u001b[0m, in \u001b[0;36mDriverFinder.get_path\u001b[0;34m(service, options)\u001b[0m\n\u001b[1;32m     38\u001b[0m     path \u001b[38;5;241m=\u001b[39m SeleniumManager()\u001b[38;5;241m.\u001b[39mdriver_location(options) \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m path\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m---> 40\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to obtain driver for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcapabilities\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbrowserName\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m using Selenium Manager.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NoSuchDriverException(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Path(path)\u001b[38;5;241m.\u001b[39mis_file():\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'capabilities'"
     ]
    }
   ],
   "source": [
    "target_url = \"https://docs.oracle.com/en-us/iaas/api/#/\"  # Replace with the URL you want to scrape\n",
    "found_urls = extract_urls_with_js(target_url)\n",
    "\n",
    "print(\"Found URLs:\")\n",
    "for url in found_urls:\n",
    "    print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-13T16:19:58.593491Z",
     "start_time": "2023-06-13T16:19:58.585704Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "def save_content(link_list):\n",
    "    for i, link in enumerate(link_list):\n",
    "        html_data = get_data(link)\n",
    "        soup = BeautifulSoup(html_data, \"html.parser\")\n",
    "        text = soup.get_text()\n",
    "\n",
    "        # Remove the first 835 lines\n",
    "        lines = text.splitlines()\n",
    "        cleaned_text = \"\\n\".join(lines)\n",
    "\n",
    "        # Get the first 3 words in the cleaned text\n",
    "        words = cleaned_text.split()[:3]\n",
    "        file_name_prefix = \"_\".join(words)\n",
    "\n",
    "        # Replace special characters and spaces with an underscore\n",
    "        file_name_prefix = re.sub(r\"[^a-zA-Z0-9]+\", \"_\", file_name_prefix)\n",
    "\n",
    "        # Get the current working directory\n",
    "        current_dir = os.getcwd()\n",
    "\n",
    "        # Move up one level to the parent directory\n",
    "        parent_dir = os.path.dirname(current_dir)\n",
    "\n",
    "        # Set the path to the data folder\n",
    "        data_folder = os.path.join(parent_dir, \"data/langchain_doc\")\n",
    "\n",
    "        # Create the data folder if it doesn't exist\n",
    "        if not os.path.exists(data_folder):\n",
    "            os.makedirs(data_folder)\n",
    "\n",
    "        # Set the path to the output file\n",
    "        output_file = os.path.join(data_folder, f\"{i}_{file_name_prefix}.txt\")\n",
    "\n",
    "        # Save the cleaned content to the output file\n",
    "        with open(output_file, \"w\") as f:\n",
    "            f.write(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-13T16:27:42.481314Z",
     "start_time": "2023-06-13T16:19:59.394583Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# save the content of the links into txt files\n",
    "save_content(found_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Q&A bot with langchain over a directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T16:41:39.120259Z",
     "start_time": "2023-06-19T16:41:37.999101Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import os\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import DirectoryLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T16:41:51.728890Z",
     "start_time": "2023-06-19T16:41:51.721987Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Create a new openai api key\n",
    "import os\n",
    "\n",
    "api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-Your key\"\n",
    "# set up openai api key\n",
    "openai_api_key = os.environ.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T16:42:12.868777Z",
     "start_time": "2023-06-19T16:41:56.716136Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/zhuoli/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/zhuoli/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print number of txt files in directory\n",
    "loader = DirectoryLoader('/home/zhuoli/Projects/github/zhuoli/data/langchain_doc', glob=\"./*.txt\")\n",
    "doc = loader.load ( )\n",
    "len(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T16:42:15.006310Z",
     "start_time": "2023-06-19T16:42:14.844815Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Splitting the text into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter (chunk_size=1000, chunk_overlap=200)\n",
    "texts = text_splitter.split_documents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T16:42:15.204405Z",
     "start_time": "2023-06-19T16:42:15.197499Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of chunks\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T16:42:16.482727Z",
     "start_time": "2023-06-19T16:42:16.460830Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content=\"Cloud Free Tier | Oracle\\n\\nAccessibility Policy\\n\\nSkip to content\\n\\nAbout\\n\\nServices\\n\\nSolutions\\n\\nPricing\\n\\nPartners\\n\\nResources\\n\\nClose Search\\n\\nClose\\n\\nWe’re sorry. We could not find a match for your search. We suggest you try the following to help find what you're looking for:\\n\\nCheck the spelling of your keyword search. Use synonyms for the keyword you typed, for example, try “application” instead of “software.” Start a new search.\\n\\nClear Search\\n\\nSearch\\n\\nMenu\\n\\nMenu\\n\\nContact Sales\\n\\nSign in to Oracle Cloud\\n\\nCloud\\n\\nOracle Cloud Free Tier Build, test, and deploy applications on Oracle Cloud—for free. New Always Free services have been added, including Arm Ampere A1 Compute. For large-scale Arm development projects you can apply for  OCI Arm Accelerator.\\n\\nStart for free Sign in to Oracle Cloud\\n\\nOracle Cloud Infrastructure Always Free Services (0:38)\\n\\nWhat's included with Oracle Cloud Free Tier? *\\n\\nAlways Free services Services you can use for an unlimited time.\", metadata={'source': '/home/zhuoli/Projects/github/zhuoli/data/langchain_doc/5_Cloud_Free_Tier.txt'})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the first chunk\n",
    "texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /home/zhuoli/.pyenv/versions/3.10.9/lib/python3.10/site-packages (0.27.9)\n",
      "Requirement already satisfied: aiohttp in /home/zhuoli/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from openai) (3.8.4)\n",
      "Requirement already satisfied: requests>=2.20 in /home/zhuoli/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from openai) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /home/zhuoli/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/zhuoli/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from requests>=2.20->openai) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/zhuoli/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from requests>=2.20->openai) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/zhuoli/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from requests>=2.20->openai) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/zhuoli/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from requests>=2.20->openai) (2.10)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/zhuoli/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/zhuoli/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from aiohttp->openai) (23.1.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/zhuoli/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/zhuoli/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/zhuoli/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from aiohttp->openai) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/zhuoli/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from aiohttp->openai) (4.0.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting tiktoken\n",
      "  Using cached tiktoken-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/zhuoli/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from tiktoken) (2.31.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/zhuoli/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from tiktoken) (2023.6.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/zhuoli/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/zhuoli/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.2.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/zhuoli/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/zhuoli/.pyenv/versions/3.10.9/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2.10)\n",
      "Installing collected packages: tiktoken\n",
      "Successfully installed tiktoken-0.4.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install openai\n",
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Data base creation with ChromaDB\n",
    "\n",
    "https://www.youtube.com/watch?v=3yPBVii7Ct0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T16:43:22.594752Z",
     "start_time": "2023-06-19T16:42:18.312526Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Embed and store the texts\n",
    "# Supplying a persist_directory will store the embeddings on disk\n",
    "persist_directory = 'db'\n",
    "\n",
    "# OpenAI embeddings\n",
    "embedding = OpenAIEmbeddings()\n",
    "\n",
    "vectordb = Chroma.from_documents(documents=texts,\n",
    "                                 embedding=embedding,\n",
    "                                 persist_directory=persist_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T16:43:27.867043Z",
     "start_time": "2023-06-19T16:43:22.595566Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Persist the db to disk\n",
    "vectordb.persist()\n",
    "vectordb = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T16:43:31.243716Z",
     "start_time": "2023-06-19T16:43:29.911945Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Now we can load the persisted database from disk, and use it as normal.\n",
    "vectordb = Chroma(persist_directory=persist_directory,\n",
    "                  embedding_function=embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Create retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T16:26:30.027619Z",
     "start_time": "2023-06-19T16:26:30.025333Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T16:26:30.878277Z",
     "start_time": "2023-06-19T16:26:30.666287Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "docs = retriever.get_relevant_documents(\"write a resignation letter for me, my last day is this Friday, and I'm happy to leave this shithole\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T16:26:31.158685Z",
     "start_time": "2023-06-19T16:26:31.152005Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Moved', metadata={'source': '/home/zhuoli/Projects/github/zhuoli/data/langchain_doc/2_Moved.txt'}),\n",
       " Document(page_content='Moved', metadata={'source': '/home/zhuoli/Projects/github/zhuoli/data/langchain_doc/12_Moved.txt'}),\n",
       " Document(page_content='Submit\\n\\nPlease complete this form and a sales representative will contact you. (change)\\n\\nI’m an Oracle customer who needs support Get technical, billing, and account questions answered.\\n\\nI need technical support\\n\\nFind the\\n\\ncustomer support\\n\\nyou need.\\n\\nUse the following information to get technical help:', metadata={'source': '/home/zhuoli/Projects/github/zhuoli/data/langchain_doc/15_Oracle_Contacts_Click.txt'}),\n",
       " Document(page_content='Please select product category\\n\\nCloud Applications\\n\\nCloud Infrastructure\\n\\nDatabase\\n\\nJava\\n\\nLinux\\n\\nIndustry Solutions\\n\\nOn\\n\\n\\n\\nPremise Products\\n\\nProduct\\n\\nPlease select product Sales, Marketing, and Commerce Service and Field Service Financial (ERP/EPM/Procurement) Supply Chain Management and Manufacturing Human Capital Management Analytics Compute/Block Storage Networking Integration Security, Management and Governance Application Development Middleware Oracle Database Autonomous and Database Cloud Services MySQL Big Data Exadata and Database Appliances Java GraalVM Linux VirtualBox Container Platform Communication Applications Communications Network & SBC Construction Project Management Financial Services Food and Beverage Health Sciences Hospitality Retail Utilities GraalVM Linux Engineered Systems Server & Storage Systems eBusiness Suite JD Edwards Peoplesoft Siebel\\n\\nSubmit\\n\\nPlease complete this form and a sales representative will contact you. (change)', metadata={'source': '/home/zhuoli/Projects/github/zhuoli/data/langchain_doc/15_Oracle_Contacts_Click.txt'})]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T16:26:31.757606Z",
     "start_time": "2023-06-19T16:26:31.753080Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T16:26:32.357106Z",
     "start_time": "2023-06-19T16:26:32.352369Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T16:26:32.812894Z",
     "start_time": "2023-06-19T16:26:32.810205Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'similarity'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.search_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T16:26:34.043554Z",
     "start_time": "2023-06-19T16:26:34.016639Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'k': 2}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.search_kwargs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Create a question answering chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T16:27:30.194519Z",
     "start_time": "2023-06-19T16:27:30.192880Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Create the chain to answer questions\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=OpenAI(),\n",
    "                                  chain_type=\"stuff\",\n",
    "                                  retriever=retriever,\n",
    "                                  return_source_documents=True,\n",
    "                                  verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T16:27:30.714970Z",
     "start_time": "2023-06-19T16:27:30.710251Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Cite sources\n",
    "def process_llm_response(llm_response):\n",
    "    print(llm_response['result'])\n",
    "    print('\\n\\nSources:')\n",
    "    for source in llm_response[\"source_documents\"]:\n",
    "        print(source.metadata['source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T16:27:34.967867Z",
     "start_time": "2023-06-19T16:27:31.647843Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " I am writing to formally resign from my current position, effective this Friday. It has been a pleasure working here, but I am ready to move on to something new. Thank you for the opportunity.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/home/zhuoli/Projects/github/zhuoli/data/langchain_doc/2_Moved.txt\n",
      "/home/zhuoli/Projects/github/zhuoli/data/langchain_doc/12_Moved.txt\n"
     ]
    }
   ],
   "source": [
    "# Question\n",
    "query = \"write a resignation letter for me, my last day is this Friday, and I'm happy to leave this shithole\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T16:28:07.848794Z",
     "start_time": "2023-06-19T16:28:02.784404Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Break it down\n",
    "query = \"What are all agent types?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)\n",
    "#llm_response\n",
    "\n",
    "qa_chain.retriever.search_type , qa_chain.retriever.vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T16:28:15.148649Z",
     "start_time": "2023-06-19T16:28:15.140236Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "{context}\n",
      "\n",
      "Question: {question}\n",
      "Helpful Answer:\n"
     ]
    }
   ],
   "source": [
    "print(qa_chain.combine_documents_chain.llm_chain.prompt.template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Deleteing the DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-13T17:27:10.552238Z",
     "start_time": "2023-06-13T17:27:05.048974Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating: db/ (stored 0%)\r\n",
      "updating: db/chroma-embeddings.parquet (deflated 29%)\r\n",
      "updating: db/index/ (stored 0%)\r\n",
      "updating: db/index/index_metadata_b9a5e02f-ebd0-4b13-8858-b30b211c4546.pkl (deflated 5%)\r\n",
      "updating: db/index/id_to_uuid_b9a5e02f-ebd0-4b13-8858-b30b211c4546.pkl (deflated 37%)\r\n",
      "updating: db/index/uuid_to_id_d80886e4-65e1-4231-8c73-99ff58d68061.pkl (deflated 39%)\r\n",
      "updating: db/index/index_b9a5e02f-ebd0-4b13-8858-b30b211c4546.bin (deflated 17%)\r\n",
      "updating: db/index/index_d80886e4-65e1-4231-8c73-99ff58d68061.bin (deflated 17%)\r\n",
      "updating: db/index/uuid_to_id_b9a5e02f-ebd0-4b13-8858-b30b211c4546.pkl (deflated 41%)\r\n",
      "updating: db/index/id_to_uuid_d80886e4-65e1-4231-8c73-99ff58d68061.pkl (deflated 32%)\r\n",
      "updating: db/index/index_metadata_d80886e4-65e1-4231-8c73-99ff58d68061.pkl (deflated 5%)\r\n",
      "updating: db/chroma-collections.parquet (deflated 50%)\r\n",
      "updating: db/.DS_Store (deflated 96%)\r\n"
     ]
    }
   ],
   "source": [
    "!zip -r db.zip ./db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-13T17:27:10.802965Z",
     "start_time": "2023-06-13T17:27:10.552089Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# To clean up, you can delete the collection\n",
    "vectordb.delete_collection()\n",
    "vectordb.persist()\n",
    "\n",
    "# Delete the directory\n",
    "!rm -rf db/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Starting again loading the db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T16:30:09.309839Z",
     "start_time": "2023-06-19T16:29:00.698188Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  db.zip\r\n",
      "replace db/chroma-embeddings.parquet? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\r\n"
     ]
    }
   ],
   "source": [
    "!unzip db.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T16:30:13.801920Z",
     "start_time": "2023-06-19T16:30:12.530863Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB with persistence: data will be stored in: db\n"
     ]
    }
   ],
   "source": [
    "persist_directory = 'db'\n",
    "embedding = OpenAIEmbeddings()\n",
    "\n",
    "vectordb2 = Chroma(persist_directory=persist_directory,\n",
    "                  embedding_function=embedding,\n",
    "                   )\n",
    "\n",
    "retriever = vectordb2.as_retriever(search_kwargs={\"k\": 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Usung turbo GPT API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T16:30:15.131031Z",
     "start_time": "2023-06-19T16:30:15.126008Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Set up the turbo LLM\n",
    "turbo_llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    model_name='gpt-3.5-turbo'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T16:30:15.535025Z",
     "start_time": "2023-06-19T16:30:15.531668Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Create the chain to answer questions\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=turbo_llm,\n",
    "                                  chain_type=\"stuff\",\n",
    "                                  retriever=retriever,\n",
    "                                  return_source_documents=True,\n",
    "                                  verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T16:30:16.283860Z",
     "start_time": "2023-06-19T16:30:16.275813Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Cite sources\n",
    "def process_llm_response(llm_response):\n",
    "    print(llm_response['result'])\n",
    "    print('\\n\\nSources:')\n",
    "    for source in llm_response[\"source_documents\"]:\n",
    "        print(source.metadata['source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T16:30:22.264885Z",
     "start_time": "2023-06-19T16:30:16.942379Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "There are two main types of agents mentioned in the context: Action Agents and Plan-and-Execute Agents. Action Agents decide the actions to take and execute those actions one at a time, while Plan-and-Execute Agents first decide a plan of actions to take, and then execute those actions one at a time.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/Users/erictak/PycharmProjects/langchain/data/langchain_doc/639_Agents_Contents_Action.txt\n",
      "/Users/erictak/PycharmProjects/langchain/data/langchain_doc/344_Agents_Contents_Action.txt\n"
     ]
    }
   ],
   "source": [
    "# Question\n",
    "query = \"What are the agent types?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T16:30:23.332015Z",
     "start_time": "2023-06-19T16:30:23.325565Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use the following pieces of context to answer the users question. \n",
      "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "----------------\n",
      "{context}\n"
     ]
    }
   ],
   "source": [
    "print(qa_chain.combine_documents_chain.llm_chain.prompt.messages[0].prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T16:30:24.189842Z",
     "start_time": "2023-06-19T16:30:24.183626Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{question}\n"
     ]
    }
   ],
   "source": [
    "print(qa_chain.combine_documents_chain.llm_chain.prompt.messages[1].prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T16:30:24.724602Z",
     "start_time": "2023-06-19T16:30:24.717401Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Visualizing the Vector db\n",
    "https://github.com/mtybadger/chromaviz?ref=reactjsexample.com\n",
    "\n",
    "https://github.com/avantrio/chroma-viewer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from chromaviz import visualize_collection\n",
    "visualize_collection(vectordb._collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
